[
  {
    "id": "chunk_000000",
    "text": "Recap of Operating Systems • The following OS concepts are required to understand virtualization • The concept of a process • Virtual memory, paging, (segmentation) • User mode and kernel mode of a process • Interrupt/trap processing in kernel mode • I/O handling The concept of a process • A process is a running program • User writes a program, compiles it to generate an executable • Executable contains machine/CPU instructions • Every CPU architecture (e.g., x86) defines a certain set of instructions • Compiler translates high level language code to instructions the CPU can run • To create a process, OS allocates memory in RAM for the memory image of the process, containing • Code and static/global data from the executable • Heap memory for dynamic memory allocations (e.g., malloc) • Stack to store arguments/return address/local variables during function calls • All instructions and variables in the memory image are assigned memory addresses • Starting at 0, up to some max value (4GB in 32-bit systems) Memory image of a process Code/data Heap Stack ….. Address = 0 Address = 12KB Max Address = 4GB from compiled executable (machine instructions, static/global data) Address of this memory returned by malloc New stack frame pushed by function call Contains arguments, local vars, return address etc. Popped when function returns Heap and stack grow towards each other Unused addresses Process execution • When a process is run, CPU executes the code in the memory image • When a process runs on the CPU, the CPU registers hold values related to the process execution • The program counter (PC, or EIP in x86) has address of current instruction • The CPU fetches the current instruction, decodes it, and executes it • Any variables needed for operations are loaded from process memory into general purpose CPU registers (EAX, EBX, ECX, EDX etc in x86) • After instruction completes, values are stored from registers into memory • The stack pointer (SP, or ESP in x86) has address of top of stack (current stack frame holds arguments/variables of the current function that is running) • The set of values of all CPU registers pertaining to a process execution is called its CPU context CPU context during execution Code/data Heap Stack ….. CPU EIP (PC) EAX EDX ….. ESP Concurrent execution, context switching • To run a process,",
    "source_file": "02-OS-review.pdf"
  },
  {
    "id": "chunk_000001",
    "text": "CPU registers pertaining to a process execution is called its CPU context CPU context during execution Code/data Heap Stack ….. CPU EIP (PC) EAX EDX ….. ESP Concurrent execution, context switching • To run a process, OS allocates memory, loads CPU context • EIP points to instructions, ESP points to stack of process, registers have process data • CPU now begins to run the process • OS runs multiple process concurrently by multiplexing on the same CPU • Context switch: After running a process for some time, OS switches from one process to another • How does context switch happen? OS saves the CPU context of the old process and loads the context of new process • When EIP points to instruction of new process, new process starts to run • Where is the context saved? • OS has a data structure called Process Control Block (PCB) for each process • PCB (specifically, a PCB field called kernel stack) temporarily stores context of a process when it is not running Context switch Code/data Heap Stack ….. CPU EIP (PC) EAX EDX ….. ESP Code/data Heap Stack ….. Process control blocks User memory Kernel memory EIP (PC) EAX EDX ….. ESP CPU has switched execution from blue process to green process Virtual memory • Addresses assigned in memory image, that are used by CPU to load and store are virtual/logical addresses • These virtual addresses are not actual addresses occupied by instructions/data of process, but assigned from 0 for convenience • Actual addresses where instructions/data bytes of process are stored are called physical addresses • RAM hardware needs physical addresses to fetch bytes • CPU requests code/data at virtual addresses • Translated to physical address so that RAM can fetch it • Memory is allocated at granularity of pages (usually 4KB) • Logical pages of a process are stored in physical frames in memory • Logical page numbers translated to physical frame numbers Virtual and physical address spaces Code/data Heap Stack ….. Address = 0 Address = 4GB Virtual address space Physical address space Address = X Address = Y Address = Z Page (4KB) CPU Fetch address 5KB Fetch address Y+1KB Address translation with paging • On every memory access, a piece of hardware called MMU (memory management unit) translates virtual addresses to physical addresses • Page table of a process stores the mapping of logical page number  physical frame number • OS builds the page table when allocation memory • MMU uses this page",
    "source_file": "02-OS-review.pdf"
  },
  {
    "id": "chunk_000002",
    "text": ", a piece of hardware called MMU (memory management unit) translates virtual addresses to physical addresses • Page table of a process stores the mapping of logical page number  physical frame number • OS builds the page table when allocation memory • MMU uses this page table to translate addresses • MMU looks up CR3 register of CPU (x86) which stores location of page table of current process • Looks up page number in page table to translate address • CR3 reset on every context switch • Recent address translations cached in TLB (Translation Lookaside Buffer) located within MMU Page number Offset Frame number Offset Virtual address Physical address Using page table Page CPU Fetch address 5KB Fetch address Y+1KB Virtual address space Physical address space Address = Y Address = Z Address = X CR3 MMU Page table (page 1 = frame y) Hierarchical page tables • Modern operating systems use hierarchical page tables • 32-bit virtual address space (4GB), 2^12 byte (4KB) pages • Each process can have up to 2^32/2^12 = 2^20 pages • Each page has a page table entry (PTE), so 2^20 PTEs per process • Assuming each PTE is 4 bytes, all page table entries occupy 4*2^20 = 4MB • Cannot store a large page table contiguously in memory, so page table of a process is stored in memory in page sized chunks • Each 4KB page stores 2^10 PTEs, so 2^20/2^10 = 2^10 pages to store all PTEs • Pointers to these “inner” pages stored in an outer page directory • In 32-bit architectures, one outer page can store physical frame numbers of all 2^10 inner page table pages, so 2-level page table • More levels in page table for 64-bit architectures Page table lookup (walking the page table) PTE Page table entry stores physical frame number 2^32/2^12 = 2^20 pages 2^20 PTEs in 2^10 pages Array of PTEs Split among multiple pages Physical frame numbers of 2^10 inner pages stored in outer page directory CPU’s CR3 has physical address of outermost page directory 10 bits Virtual address MMU 10 bits 12-bit offset Frame number Offset Physical address Multiple such levels of page tables can exist Mapping cached in TLB Demand Paging Code/data Heap Stack ….. Address = 0 Address = 4GB Virtual address space Physical address",
    "source_file": "02-OS-review.pdf"
  },
  {
    "id": "chunk_000003",
    "text": "MMU 10 bits 12-bit offset Frame number Offset Physical address Multiple such levels of page tables can exist Mapping cached in TLB Demand Paging Code/data Heap Stack ….. Address = 0 Address = 4GB Virtual address space Physical address space Address = X Address = Y Address = Z Page CPU Fetch address 5KB Page fault Another victim page swapped to disk Physical frame assigned to page Page table updated CPU instruction rerun User mode and kernel mode • Two kinds of CPU instructions • Unprivileged instructions (regular program code) – part of user code • Privileged instructions (access to hardware etc.) – part of OS code • Modern CPUs have multiple privilege levels (rings) • Privileged instructions are executed only when CPU is at high privilege level • User code runs at low privilege level / user mode (CPU set to ring 3 in x86) • If user runs privileged instructions, error is thrown • OS code runs at high privilege level / kernel mode (CPU set to ring 0 in x86) • Allowed to run privileged instructions • Privilege level checked by CPU and MMU (every page has privilege bit) • When user process needs to perform privileged action, must jump to privileged OS code, set CPU to high privilege, and then perform the action Where is OS code located? • OS is part of high virtual address space of every process • Page table of process maps these kernel addresses to location of kernel code in memory • Only one copy of OS code in memory, but mapped into virtual address space/page table of every process • Process jumps to high virtual addresses to run OS code Code/data Heap Stack ….. Address = 0 Address = 3GB OS Address = 4GB Kernel code in memory Virtual address space Physical address space Page Address = X Kernel mode execution • When does a process go from user mode to kernel mode? • System call: user requests some privileged action from OS (e.g., read syscall) • Program fault: hardware raises a fault when user does some invalid action (e.g., privileged instruction in user mode, page fault) • Interrupt: I/O devices request attention (e.g., packet has arrived on NIC) • All these are called traps in general • How is a trap handled? • Change CPU privilege level to high privilege/kernel mode • Jump to OS code that handles trap and run it • Return to user code after handling trap • Can choose to return to user code of another process too (if context switch) What happens upon a trap",
    "source_file": "02-OS-review.pdf"
  },
  {
    "id": "chunk_000004",
    "text": "CPU privilege level to high privilege/kernel mode • Jump to OS code that handles trap and run it • Return to user code after handling trap • Can choose to return to user code of another process too (if context switch) What happens upon a trap? • Trap handling begins by running a CPU instruction (int n in x86) • Invoked by system call code or triggered by hardware event • What happens during execution of int n? • Change CPU privilege level • Lookup Interrupt Descriptor Table (IDT) with index “n” to get address of kernel code that handles this trap set EIP to this value • Use kernel stack of process (in PCB) as the main stack set ESP to this value • Start saving user context onto the (kernel) stack • Next, kernel code to handle the trap runs • Save more user context, beyond what is saved by hardware instruction • System call processing, interrupt handling etc. • Finally, kernel invokes iret (x86) instruction to return back to user mode • Reverses changes of int n Trap handling Code/data Heap Stack ….. CPU EIP (PC) EAX EDX ….. ESP OS ring 0 Set EIP = IDT[n] Set ESP = top of kernel stack int n executed Kernel stack of process (part of PCB kernel data structure) User context saved Interrupt Descriptor Table (IDT) • Every interrupt has a number (IRQ) • E.g., different hardware devices get different numbers, system call gets a different number • IDT has an entry for every interrupt number (IRQ) • IDT entry specifies values of EIP and a few such CPU registers • CPU uses this EIP to locate kernel interrupt handling code • Pointer to IDT is stored in CPU register • Setting IDT pointer in CPU is a privileged operation, done by OS • Much like how setting CR3 to page table is a privileged operation I/O subsystem: system calls, interrupts • Processes use system calls to access I/O devices • Process P1 makes system call, goes into kernel mode • OS device driver initiates I/O request to device (e.g., disk, network card) • If the system call is blocking (i.e., cannot be completed right away), OS performs context switch to another process P2 • When request completes, I/O device raises interrupt • P2 goes into kernel mode, handles interrupt, marks P1 as",
    "source_file": "02-OS-review.pdf"
  },
  {
    "id": "chunk_000005",
    "text": "is blocking (i.e., cannot be completed right away), OS performs context switch to another process P2 • When request completes, I/O device raises interrupt • P2 goes into kernel mode, handles interrupt, marks P1 as ready to run • P1 runs at a later time when scheduled by OS scheduler • DMA: I/O devices perform Direct Memory Access to store I/O data in memory • When initiating I/O request, device driver provides (physical) address of memory buffer in which to store I/O data (e.g., disk block) • Device first stores data in DMA buffer before raising interrupt • Interrupt handler need not copy data from device memory to RAM Summary of OS concepts • The concept of a process, memory image, CPU context • CPU context is saved in PCB/kernel stack during user/kernel mode transitions of a process, as well as during context switch between processes • Virtual memory, paging, address translation by MMU using page table • OS is mapped into the virtual address space of every process • Modern OSes use flat segments + paging • User mode and kernel mode of a process, privileged instructions, CPU privilege levels • Privileged instructions in OS code run at highest CPU privilege level (ring 0) • Interrupt/trap processing in kernel mode • Change privilege level, save user context, jump to kernel code, handle trap • I/O handling",
    "source_file": "02-OS-review.pdf"
  },
  {
    "id": "chunk_000006",
    "text": "CS 695: Virtualization and Cloud Computing Lecture 3: Techniques to design Virtual Machine Monitors Mythili Vutukuru IIT Bombay Spring 2021 Techniques to Design Virtual Machine Monitors What does VMM do? • Multiple VMs running on a PM – multiplex the underlying machine • Similar to how OS multiplexes processes on CPU • VMM performs machine switch (much like context switch) • Run a VM for a bit, save context and switch to another VM, and so on… • What is the problem? • Guest OS expects to have unrestricted access to hardware, runs privileged instructions, unlike user processes • But one guest cannot get access, must be isolated from other guests VM VMM VM VM VM Proc OS Proc Proc Proc Trap and emulate VMM (1) • All CPUs have multiple privilege levels • Ring 0,1,2,3 in x86 CPUs • Normally, user process in ring 3, OS in ring 0 • Privileged instructions only run in ring 0 • Now, user process in ring 3, VMM/host OS in ring 0 • Guest OS must be protected from guest apps • But not fully privileged like host OS/VMM • Can run in ring 1? • Trap-and-emulate VMM: guest OS runs at lower privilege level than VMM, traps to VMM for privileged operation Guest app (ring 3) Guest OS (ring 1) VMM / Host OS (ring 0) Trap and emulate VMM (2) • Guest app has to handle syscall/interrupt • Special trap instr (int n), traps to VMM • VMM doesn’t know how to handle trap • VMM jumps to guest OS trap handler • Trap handled by guest OS normally • Guest OS performs return from trap • Privileged instr, traps to VMM • VMM jumps to corresponding user process • Any privileged action by guest OS traps to VMM, emulated by VMM • Example: set IDT, set CR3, access hardware • Sensitive data structures like IDT must be managed by VMM, not guest OS Guest app (ring 3) Guest OS (ring 1) VMM / Host OS (ring 0) Trap and emulate Problems with trap and emulate • Guest OS may realize it is running at lower privilege level • Some registers in x86 reflect CPU privilege level (code segment/CS) • Guest OS can read these values and get offended! • Some x86 instructions which change hardware",
    "source_file": "03-vmm.pdf"
  },
  {
    "id": "chunk_000007",
    "text": "and emulate • Guest OS may realize it is running at lower privilege level • Some registers in x86 reflect CPU privilege level (code segment/CS) • Guest OS can read these values and get offended! • Some x86 instructions which change hardware state (sensitive instructions) run in both privileged and unprivileged modes • Will behave differently when guest OS is in ring 0 vs in less privileged ring 1 • OS behaves incorrectly in ring1, will not trap to VMM • Why these problems? • OSes not developed to run at a lower privilege level • Instruction set architecture of x86 is not easily virtualizable (x86 wasn’t designed with virtualization in mind) Example: Problems with trap and emulate • Eflags register is a set of CPU flags • IF (interrupt flag) indicates if interrupts on/off • Consider the popf instruction in x86 • Pops values on top of stack and sets eflags • Executed in ring 0, all flags set normally • Executed in ring 1, only some flags set • IF is not set as it is privileged flag • So, popf is a sensitive instruction, not privileged, does not trap, behaves differently when executed in different privilege levels • Guest OS is buggy in ring 1 CPU EIP EAX EDX ….. Eflags Code/data Heap Stack ….. Popek Goldberg theorem • Sensitive instruction = changes hardware state • Privileged instruction = runs only in privileged mode • Traps to ring 0 if executed from unprivileged rings • In order to build a VMM efficiently via trap-and-emulate method, sensitive instructions should be a subset of privileged instructions • x86 does not satisfy this criteria, so trap and emulate VMM is not possible Sensitive instructions Privileged instructions CPU instructions x86 Techniques to virtualize x86 (1) • Paravirtualization: rewrite guest OS code to be virtualizable • Guest OS won’t invoke privileged operations, makes “hypercalls” to VMM • Needs OS source code changes, cannot work with unmodified OS • Example: Xen hypervisor • Full virtualization: CPU instructions of guest OS are translated to be virtualizable • Sensitive instructions translated to trap to VMM • Dynamic (on the fly) binary translation, so works with unmodified OS • Higher overhead than paravirtualization • Example: VMWare workstation Techniques to virtualize x86 (2) • Hardware assisted virtualization:",
    "source_file": "03-vmm.pdf"
  },
  {
    "id": "chunk_000008",
    "text": "MM • Dynamic (on the fly) binary translation, so works with unmodified OS • Higher overhead than paravirtualization • Example: VMWare workstation Techniques to virtualize x86 (2) • Hardware assisted virtualization: KVM/QEMU in Linux • CPU has a special VMX mode of execution • X86 has 4 rings on non-VMX root mode, another 4 rings in VMX mode • VMM enters VMX mode to run guest OS in (special) ring 0 • Exit back to VMM on triggers (VMM retains control) Guest app (ring 3) Guest OS (ring 0) Host app (ring 3) VMM / Host OS (ring 0) Non-VMX root mode VMX mode Enter VMX mode to run VM Exit to trap to VMM Memory virtualization • What about address translation in virtual machines? Page Guest Virtual Addresses (GVA) Guest Physical Addresses (GPA) Address = Y Address = Z Address = X Host/Machine Physical Addresses (HPA) Address = Y’ Address = Z’ Address = X’ Guest page table VMM / Host page table Techniques for memory virtualization • Guest page table has GVAGPA mapping • Each guest OS thinks it has access to all RAM starting at address 0 • VMM / Host OS has GPAHPA mapping • Guest “RAM” pages are distributed across host memory • Which page table should MMU use? • Shadow paging: VMM creates a combined mapping GVAHPA and MMU is given a pointer to this page table • VMM tracks changes to guest page table and updates shadow page table • Extended page tables (EPT): MMU hardware is aware of virtualization, takes pointers to two separate page tables • Address translation walks both page tables • EPT is more efficient but requires hardware support I/O Virtualization • Guest OS needs to access I/O devices, but cannot give full control of I/O to any one guest OS • Two main techniques for I/O virtualization: • Emulation: guest OS I/O operations trap to VMM, emulated by doing I/O in VMM/host OS • Direct I/O or device passthrough: assign a slice of a device directly to each VM • Many optimizations exist, active area of research Summary • Techniques for CPU virtualization • Paravirtualization: rewrite guest OS source code • Full virtualization: dynamic binary translation • Hardware-assisted",
    "source_file": "03-vmm.pdf"
  },
  {
    "id": "chunk_000009",
    "text": "slice of a device directly to each VM • Many optimizations exist, active area of research Summary • Techniques for CPU virtualization • Paravirtualization: rewrite guest OS source code • Full virtualization: dynamic binary translation • Hardware-assisted virtualization: CPU has special virtualization mode • Techniques for memory virtualization: • Shadow page tables: combined GVAHPA mappings • Extended page tables: MMU is given separate GVAGPA and GPAHPA mappings • I/O virtualization: emulation, device passthrough • VMMs use a combination of above techniques • We will study all of the above techniques in detail",
    "source_file": "03-vmm.pdf"
  },
  {
    "id": "chunk_000010",
    "text": "CS 695: Virtualization and Cloud Computing Lecture 4: Hardware-assisted CPU virtualization in KVM/QEMU Mythili Vutukuru IIT Bombay Spring 2021 Hardware-assisted CPU Virtualization in KVM/QEMU Hardware-assisted Virtualization • Modern technique, after hardware support for virtualization introduced in CPUs • Original x86 CPUs did not support virtualization • Intel VT-X or AMD-V support is widely available in modern systems • Special CPU mode of operation called VMX mode for running VMs • Many hypervisors use this H/W feature, e.g., QEMU/KVM in Linux QEMU (Userspace process) KVM (kernel module) CPU with VMX mode Works with binary translation if no hardware support Sets up guest VM memory as part of userspace process When invoked, KVM switches to VMX mode to run guest CPU switches between VMX and non-VMX root modes Libvirt and QEMU/KVM • When you install QEMU/KVM on Linux, libvirt is also installed • A set of tools manage hypervisors, including QEMU/KVM • A daemon runs on the system and communicates with hypervisors • Exposes an API using which hypervisors can be managed, VM created etc. • Commandline tool (virsh) and GUI (virt-manager) use this API to manage VMs QEMU (Userspace process) KVM (kernel module) CPU with VMX mode virsh, virt-manager and other tools Libvirt API QEMU architecture • QEMU is userspace process • KVM exposes a dummy device • QEMU talks to KVM via open/ioctl syscalls • Allocates memory via mmap for guest VM physical memory • Creates one thread for each virtual CPU (VCPU) in guest • Multiple file descriptors to /dev/kvm (one for QEMU, one for VM, one for VCPU and so on) • ioctl on fds to talk to KVM • Host OS sees QEMU as a regular multi- threaded process QEMU (Userspace process) KVM (kernel module) (/dev/kvm) Guest VM physical memory VCPU-0 VCPU-N … QEMU operation open(/dev/kvm) ioctl(qem",
    "source_file": "04-hwvirt-kvmqemu.pdf"
  },
  {
    "id": "chunk_000011",
    "text": "U (Userspace process) KVM (kernel module) (/dev/kvm) Guest VM physical memory VCPU-0 VCPU-N … QEMU operation open(/dev/kvm) ioctl(qemu_fd, KVM_CREATE_VM) ioctl(vm_fd, KVM_CREATE_VCPU) for(;;) { //each VCPU runs this loop ioctl(vcpu_fd, KVM_RUN) switch(exit_reason) { case KVM_EXIT_IO: //do I/O case KVM_EXIT_HLT: } } This ioctl system call blocks this thread, KVM switches to VMX mode, runs guest VM Returns to QEMU on host when VM exits from VMX mode. QEMU handles exit and returns to guest VM QEMU/KVM operation QEMU (Userspace process) KVM (kernel module) Guest VM physical memory VCPU-0 ring 3 (user virt addr space) ring 0 (kernel addr space) Root mode VMX mode Guest OS Guest application 1. QEMU thread calls KVM_RUN 2. KVM shifts CPU to VMX mode 3. Guest OS and user applications run normally 4. Guest OS exits back to KVM 5. KVM handles exit or returns to QEMU thread kvm_run VCPU thread has kvm_run stucture to share info from QEMU to KVM VMX mode • Special CPU instructions to enter and exit VMX mode • VMLAUNCH, VMRESUME invoked by KVM to enter VMX mode • VMEXIT invoked by guest OS to exit VMX mode • On VMX entry/exit instructions, CPU switches context between host OS to guest OS • Page tables (address space), CPU register values etc switched • Hardware manages the mode switch • Where is CPU context stored during mode switch? • Cannot be stored in host OS or guest OS data structures alone (why?) • VMCS (VM control structure), also called VMCB (VM control block) VM control structure (VMCS) • What is VMCS? • Common memory area accessible in both modes • One VMCS per VM (KVM tells CPU which VMCS to use) • What is stored in VMCS? • Host CPU context:",
    "source_file": "04-hwvirt-kvmqemu.pdf"
  },
  {
    "id": "chunk_000012",
    "text": ") • What is VMCS? • Common memory area accessible in both modes • One VMCS per VM (KVM tells CPU which VMCS to use) • What is stored in VMCS? • Host CPU context: Stored when launching VM, restored on VM exit • Guest CPU context: Stored on VM exit, restored when VM is run • Guest entry/execution/exit control area: KVM can configure guest memory and CPU context, which instructions and events should cause VM to exit • Exit information: Exit reason and any other exit-related information • VMCS information (e.g., exit reason) exchanged with QEMU via kvm_run structure • VMCS only accessible to KVM in kernel mode, not to QEMU userspace KVM (root mode) Guest OS (VMX mode) VMCS VMX mode execution • How is guest OS execution in VMX mode different? • Restrictions on guest OS execution, configurable exits to KVM • Guest OS exits to KVM on certain instructions (e.g., I/O device access) • No hardware access to guest, emulated by KVM • Guest OS usually exits on interrupts (interrupts handled by KVM, assigned to the appropriate host or guest OS) • KVM can inject virtual interrupts to guest OS during VMX mode entry • All of the above controlled by KVM via VMCS • Mimics the trap-and-emulate architecture with hardware support • Guest runs in a (special) ring 0, but trap-and-emulate achieved QEMU/KVM operation revisited QEMU (Userspace process) KVM (kernel module) Guest VM physical memory VCPU-0 ring 3 ring 0 Root mode VMX mode Guest OS Guest application 1. QEMU thread calls KVM_RUN 2. KVM executes VMRESUME/VMLAUNCH Host context saved in VMCS, guest context restored 3. Guest OS and user applications run normally, within restrictions 4. Guest OS executes VMEXIT upon trigger Guest context saved, host restored from VMCS 5. KVM handles exit or returns to QEMU thread, with exit info in kvm_run kvm_run VMCS Host view • Host sees QEMU as regular multithreaded process • Process that has memory-mapped memory, talks to KVM device via",
    "source_file": "04-hwvirt-kvmqemu.pdf"
  },
  {
    "id": "chunk_000013",
    "text": "QEMU thread, with exit info in kvm_run kvm_run VMCS Host view • Host sees QEMU as regular multithreaded process • Process that has memory-mapped memory, talks to KVM device via ioctl calls • Multiple QEMU VCPU threads can be scheduled in parallel on multiple cores • When KVM launches a VM, host OS context is stored in VMCS • Host OS execution is suspended (all host processes stop) • CPU loads guest OS context and guest OS starts running • When guest OS exits, host OS context is restored from VMCS • Host OS resumes in KVM, where it stopped execution • KVM can return to QEMU, or host can switch to another process • Host OS is not aware of guest OS execution KVM / Host OS Guest OS QEMU VMCS Summary • Hardware-assisted CPU virtualization in QEMU/KVM • QEMU creates guest physical memory, one thread per VPCU • QEMU VCPU thread gives KVM_RUN command to KVM kernel module • KVM configures VM information in VMCS, launches guest OS in VMX mode • Guest OS runs natively on CPU until VM exit happens • Control returns to KVM/Host OS on VM exit • VM exits handled by KVM or QEMU • Host schedules QEMU like any other process, not aware of guest OS Guest OS VMX mode KVM / Host OS QEMU Root mode",
    "source_file": "04-hwvirt-kvmqemu.pdf"
  },
  {
    "id": "chunk_000014",
    "text": "CS 695: Virtualization and Cloud Computing Lecture 5: Full virtualization Mythili Vutukuru IIT Bombay Spring 2021 Full Virtualization Full virtualization • x86 and other hardware lacked virtualization support • But cloud computing increased demand for virtualization • VMWare workstation first to solve the problem of virtualization existing operating systems on x86 (basis for this lecture) • Type 2 hypervisor based on trap-and-emulate approach • Key idea: dynamic (on a need basis) binary (not source) translation of OS instructions • Problematic OS instructions translated before execution • Subsequently, hardware support for virtualization (previous lecture) • Binary translation is higher overhead than hardware-assisted virtualization • Used when hardware support not available Full virtualization VMM architecture VMM userspace process VMM kernel driver (Host OS) Guest VM physical memory ring 3 ring 0 Host OS context VMM context VMM (guest OS traps here) Guest application 1. ioctl call to run VM 2. World switch to VMM context 3. Guest OS and user applications run with less privilege 5. VMM switches back to host on interrupts, I/O requests etc. (Some traps handled by VMM without world switch) 6. VMM kernel driver or userspace process handle exits ring 1 Guest OS 4. Privileged actions trap to VMM Host and VMM contexts • Each context has separate page tables, CPU registers, IDTs and so on • VMM context: VMM occupies top 4MB of address space • Memory page containing code/data of world switch mapped in both contexts • Host/VMM context saved/restored in this special “cross” page by VMM Host user processes Host OS VMM kernel driver Guest user processes Guest OS VMM code data context World switch Memory page of world switch code/data/context mapped by both page tables Understand difference with QEMU/KVM • Where is context saved? • Common cross page mapped into both host and guest address spaces • KVM: Common memory (VMCS) accessible by CPU in both contexts via special instructions • Privilege level of guest OS? • Guest OS runs in ring 1 (lower privilege). Instructions that do not run correctly at lower privilege level are suitably translated to trap to VMM • KVM: Guest OS runs in VMX ring 0. Some privileged instructions trigger exit to KVM • How to trap to VMM? • VMM is located in top 4MB of guest address space , guest OS traps to V",
    "source_file": "05-fullvirt.pdf"
  },
  {
    "id": "chunk_000015",
    "text": "VMM • KVM: Guest OS runs in VMX ring 0. Some privileged instructions trigger exit to KVM • How to trap to VMM? • VMM is located in top 4MB of guest address space , guest OS traps to VMM for privileged ops. World switch to host if VMM cannot handle trap in guest context • KVM: VMM is not in guest context, guest traps to VMM in host via VM exit Binary translation • Guest OS binary is translated instruction-by- instruction and stored in translation cache (TC) • Part of VMM memory • Most code stays same, unmodified • OS code modified to work correctly in ring 1 • Sensitive but unprivileged instructions modified to trap • Guest OS code executes from TC in ring 1 • Privileged OS code traps to VMM • E.g., I/O, set IDT, set CR3, other privileged ops • Emulated in VMM context or by switching to host • VMM sets sensitive data structures like IDT etc. (maintains shadow copies) Guest user processes ring 3 Guest OS VMM ring 0 Translation cache (TC) ring 1 Dynamic binary translation • VMM translator logic (ring 0) translates guest code one basic block at a time to produce a compiled code fragment (CCF) • Basic block = sequence of instructions until a jump/return • Once CCF is created, move to ring 1 to run translated guest code • Once CCF ends, “call out” to VMM logic, compute next instruction to jump to, translate, run CCF, and so on • If next CCF present in TC already, then directly jump to it without invoking VMM translator logic • Optimization called chaining Guest user Guest OS VMM ring 0 Translation cache ring 1 Basic block CCF Basic block CCF Use of segmentation for protection • Paging protects user code from kernel code via bit in page table entry • Segments are”flat” • Separate flat segments for user and kernel modes • Segmentation is used to protect VMM from guest • Flat segments truncated to exclude VMM • CS of guest OS (ring 1) points to VMM • VMM (ring 0) segments point to top 4MB Host user processes Host OS Guest user processes Guest OS VMM TC User pages Kernel pages cs,ds (ring 3) cs, ds (ring 0) cs (ring 1) ds (ring 1) cs,ds (flat) Special case: GS segment (optional) • Sometimes",
    "source_file": "05-fullvirt.pdf"
  },
  {
    "id": "chunk_000016",
    "text": "processes Guest OS VMM TC User pages Kernel pages cs,ds (ring 3) cs, ds (ring 0) cs (ring 1) ds (ring 1) cs,ds (flat) Special case: GS segment (optional) • Sometimes, translated guest code (ring 1) needs to access VMM data structures like saved register values, program counters and so on • In such cases, memory accesses are rewritten to use the GS segment, e.g., virtual address “GS:someAddress” • GS register points to the 4MB VMM area in ring 1 • Ensures that the translated guest OS code can selectively access VMM data structures • Original guest code that uses GS (which is rare) is rewritten to use another segment like %fs Summary • VMWare workstation is example of full virtualization, where unmodified OS is run on x86 hardware via dynamic binary translation • VMM user process and kernel driver on host trigger world switch from host OS context to VMM context • World switch code/data is part of both host and VMM contexts, special cross page accessible in both modes has saved contexts • VMM is in top 4MB of address space in VMM context • Translated guest code runs in ring 1, traps to VMM in ring 0 for privileged operations (trap-and-emulate) • Traps handled by VMM in ring 0, or VMM exits to host OS for emulation • Segmentation used to protect VMM from guest OS • “Bringing Virtualization to the x86 Architecture with the Original VMware Workstation”, Edouard Bugnion, Scott Devine, Mendel Rosenblum, Jeremy Sugerman, Edward Y. Wang. • “A Comparison of Software and Hardware Techniques for x86 Virtualization”, Keith Adams, Ole Agesen.",
    "source_file": "05-fullvirt.pdf"
  }
]